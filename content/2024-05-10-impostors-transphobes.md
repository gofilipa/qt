Title: Impostors and Transphobes: The Function Of Fear In Grad School
Date: 05-10-2024
Category: revision

Last week, I gave a talk that felt kind of like a culmination for
me. It was a keynote for my alma matter, the English department at the
Graduate Center, CUNY, for their annual ESA conference, which was
themed on graduate student work, its many manifestations, and the ways
that interdisciplinary research speaks to other work the department.

I knew I wanted to talk about my own fears throughout graduate school,
of impostor syndrome, which for me manifested most strongly as a fear
of public speaking. So I used that as a launch point. Then I went into
reading practices in literary studies, using Eve Kosofsky Sedgwick to
explore how reparative reading can take what is traditionally seen to
be repressive and turns it into a source of sustenance, of
generation. From there I moved, perhaps rather abruptly, into my
interest in studying transphobia with AI. Then, in probably what was a
very disorienting jump for my audience, I dove deeply into the
workings of text generation in machine learning tools. I talked about
word vectors and plausibility/generalization in LLMs (see [Ted
Chiang's fascinating
article](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web),
for example) and brought them into alignment with Trans Studies and
the attachment to "norms" and quotidian affects. I ended by posing
this congruence between the two, between text generation and Trans
Studies, in the tendency and desire for normalization. That's the case
I made, anyway. The [talk is accessible
here](https://github.com/gofilipa/qt/blob/main/qt_writings/keynote.pdf).

There are a lot of threads here, and I'm not sure I can bring them
fully into conversation. But the ideas are exciting. 

The next step will be to prioritize processing and cleaning the
datasets. I'm making good progress with the congressional one, but the
state one is still in PDF form. After that I will have to find the
right hyperparameters for fine-tuning. And I'm on a clock.

It's a big project. We will see what happens.



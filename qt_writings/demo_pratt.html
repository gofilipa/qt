<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-02-22 Thu 15:26 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="CaladoF" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgf7c267b">1. goals:</a></li>
<li><a href="#org7c369b4">2. class</a>
<ul>
<li><a href="#orgc7a7b83">2.1. Welcome!</a></li>
<li><a href="#org1defeae">2.2. Workshop goals:</a></li>
<li><a href="#org58ce24d">2.3. introduction to LLMs</a>
<ul>
<li><a href="#org6e2b4cc">2.3.1. How does ChatGPT work?</a></li>
<li><a href="#org044b792">2.3.2. Word Embeddings / Word Vectors</a></li>
<li><a href="#org78c0129">2.3.3. king - man + woman = queen</a></li>
</ul>
</li>
<li><a href="#orgd090786">2.4. Huggingface🤗 platform</a>
<ul>
<li><a href="#org7e2730c">2.4.1. "models hub"</a></li>
<li><a href="#org265c533">2.4.2. "datasets hub"</a></li>
<li><a href="#orgf5d133c">2.4.3. think/pair/share activity</a></li>
</ul>
</li>
<li><a href="#org22e28df">2.5. inference with python on colab: abstraction &amp; data:</a>
<ul>
<li><a href="#orgd4938e8">2.5.1. google colab, REPL, variables:</a></li>
<li><a href="#org71cabc7">2.5.2. import the models</a></li>
<li><a href="#orgc50d47f">2.5.3. run inference</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgf7c267b" class="outline-2">
<h2 id="orgf7c267b"><span class="section-number-2">1.</span> goals:</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>understanding of language models available to them and how to start
using them on their own.
<ul class="org-ul">
<li>build toward skills for using them in programming, even if you
don't have a background</li>
</ul></li>
<li>familiarity of underlying technical processes that power the tools,
like word vectors.</li>
<li>exposure to issues with training and producing LLMs, such as
particularly the perpetuation of bias and discrimination and
copyright issues.</li>
<li>hands-on experimentation with tools in Python programming language.</li>
</ul>
</div>
</div>

<div id="outline-container-org7c369b4" class="outline-2">
<h2 id="org7c369b4"><span class="section-number-2">2.</span> class</h2>
<div class="outline-text-2" id="text-2">
</div>

<div id="outline-container-orgc7a7b83" class="outline-3">
<h3 id="orgc7a7b83"><span class="section-number-3">2.1.</span> Welcome!</h3>
<div class="outline-text-3" id="text-2-1">
<p>

</p>

<p>
This workshop is a gentle introduction to using advanced AI tools, for beginners.
</p>

<p>
We will work on a popular platform for machine learning, the
HuggingFace🤗 platform, which offers tools uploaded by a community of
AI developers. We will explore and play around with these tools, which
range over various tasks and topics. 
</p>

<p>
Then, we will shift to running these tools with coding, with the
Python programming language on Google Colab.
</p>

<p>
How many people have some background with Python?
</p>
<ul class="org-ul">
<li>This workshop will be a gentle introduction to people who have never
coded with Python before.</li>
</ul>
</div>
</div>

<div id="outline-container-org1defeae" class="outline-3">
<h3 id="org1defeae"><span class="section-number-3">2.2.</span> Workshop goals:</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>understanding of language models available to them and how to start
using them on their own.</li>
<li>familiarity of underlying technical processes that power the tools,
like word vectors.</li>
<li>exposure to issues with training and producing LLMs, such as
particularly the perpetuation of bias and discrimination and
copyright issues.</li>
<li>critical reflection of methods for evaluating LLM performance.</li>
<li>hands-on experimentation with tools in Python programming language.</li>
<li>skills for importing and running models into your Python code.</li>
</ul>
</div>
</div>

<div id="outline-container-org58ce24d" class="outline-3">
<h3 id="org58ce24d"><span class="section-number-3">2.3.</span> introduction to LLMs</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Goal is to de-mystify how Large Language Models (a kind of AI
software) work under the hood.
</p>

<p>
Also to get a sense of the types of models that exist. There's a large
ecosystem of models, which can be overwhelming. 
</p>

<p>
All of this will help us in the next section, when we move to the HF
website. 
</p>
</div>

<div id="outline-container-org6e2b4cc" class="outline-4">
<h4 id="org6e2b4cc"><span class="section-number-4">2.3.1.</span> How does ChatGPT work?</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
How does it know what to respond when someone asks it a question?
</p>

<p>
More specifically, how does it know what language to generate, what
words follow other words?
</p>
<ul class="org-ul">
<li>by prediction.</li>
<li>it learns by reading. Gains an understanding of language from
processing massive amounts of text, deriving patterns.</li>
</ul>

<p>
One key development in history of AI: 
</p>
<ul class="org-ul">
<li>quantifies the meanings of words; words in text become numerical
representations (word embeddings)</li>
</ul>
</div>
</div>

<div id="outline-container-org044b792" class="outline-4">
<h4 id="org044b792"><span class="section-number-4">2.3.2.</span> Word Embeddings / Word Vectors</h4>
<div class="outline-text-4" id="text-2-3-2">

<div id="org4302511" class="figure">
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sAJdxEsDjsPMioHyzlN3_A.png" alt="1*sAJdxEsDjsPMioHyzlN3_A.png" width="500px" />
</p>
<p><span class="figure-number">Figure 1: </span>Image from "Word Embedding: Basics", by Hariom Gautam</p>
</div>

<p>
How do we turn words into something that a computer can understand?
</p>

<p>
We use "word embeddings", "word vectors."
</p>
<ul class="org-ul">
<li>technically: representations of language in vector space, graphical
space.</li>
<li>Each word is represented by a series of numbers,
with each of those numbers representing it's relationship to another
word. How closely they are related.</li>
<li>show vector for "cat" vs "dog":</li>
</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">word</th>
<th scope="col" class="org-right">tiger</th>
<th scope="col" class="org-right">cute</th>
<th scope="col" class="org-right">bones</th>
<th scope="col" class="org-right">wolf</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">cat</td>
<td class="org-right">.90</td>
<td class="org-right">.99</td>
<td class="org-right">.40</td>
<td class="org-right">.35</td>
</tr>

<tr>
<td class="org-left">dog</td>
<td class="org-right">.35</td>
<td class="org-right">.99</td>
<td class="org-right">.85</td>
<td class="org-right">.90</td>
</tr>
</tbody>
</table>


<p>
Each word is expressed as a series of numbers. Each number a different dimension of the vector.
</p>

<p>
Except we don't have just x, y, or z. We have hundreds, thousands of
vectors.
</p>

<p>
Show image from Medium.
</p>
<ul class="org-ul">
<li>More words here, along with their visualization in "vector space",
which is just a graph.</li>
</ul>

<p>
Why do this to words? Why represent them as numbers?
</p>
<ul class="org-ul">
<li>So we can do math!</li>
<li>We can do linear algebra.
<ul class="org-ul">
<li>Cat and kitten are close to each other, that means they have
similar meanings.</li>
<li>We can do cosine similarity, finding out what two vectors are
similar to each other in shape/direction actually gives us a sense
of their semantic similarity. Opens up a world of algebra,
calculus, that we can do with language.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org78c0129" class="outline-4">
<h4 id="org78c0129"><span class="section-number-4">2.3.3.</span> king - man + woman = queen</h4>
<div class="outline-text-4" id="text-2-3-3">
<p>
vector(”King”) - vector(”Man”) + vector(”Woman”) = vector("Queen")
</p>

<p>
Famous formula:
</p>
<ul class="org-ul">
<li>King - Man + Woman = Queen
<ul class="org-ul">
<li>we can do math using language! Or do language using math!?</li>
</ul></li>
<li>vector(”King”) - vector(”Man”) + vector(”Woman”) = vector("Queen")</li>
<li>Notice for a moment all the assumptions being made about gender
here.
<ul class="org-ul">
<li>That the difference between a king and a queen has to do with
gender.</li>
<li><p>
What exactly is being calculated when we subtract "man" and add
"woman"?
</p>
<ul class="org-ul">
<li>Is it biological sex that's being substracted?</li>
<li>Is it gender conventions, femininity and masculinity? Kings are
embody a masculine ideal, and queens a feminine one?</li>
<li>What qualities are being assumed to pertain to each gender and
each</li>
</ul>
<p>
role?
</p></li>
</ul></li>
<li>Not a massive deal, but interesting, because this is the formula
that introduced the power of word vectors to the world. So the
assumptions it plays on must be deeply embedded across society.</li>
</ul>

<p>
Why am I saying all this about word vectors? 
</p>
<ul class="org-ul">
<li>to de-mystify the tool.
<ul class="org-ul">
<li>these tools are not magic, they are not intuitive, possibly not
even "intelligent", they can just do a lot of math.</li>
</ul></li>
</ul>

<p>
See more:
</p>
<ul class="org-ul">
<li><a href="https://arxiv.org/abs/1301.3781">Word2Vec paper</a>, 2013.</li>
<li>(and <a href="http://jalammar.github.io/illustrated-word2vec/">great explanation by Jay Alammar</a>)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd090786" class="outline-3">
<h3 id="orgd090786"><span class="section-number-3">2.4.</span> Huggingface🤗 platform</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Now let's move to the platform we will be using, HuggingFace. 
</p>
<ul class="org-ul">
<li>HF is an AI research and development company based in Brooklyn, New
York City.</li>
<li>A platform for Machine Learning: compute &amp; collaborative spaces for
AI models, datasets, and more.
<ul class="org-ul">
<li>like a github for ML, if github had additional "hubs" for things
besides just code (datasets, papers, apps).</li>
<li>also can run software directly on the website, "platform"</li>
</ul></li>
</ul>
</div>

<div id="outline-container-org7e2730c" class="outline-4">
<h4 id="org7e2730c"><span class="section-number-4">2.4.1.</span> "models hub"</h4>
<div class="outline-text-4" id="text-2-4-1">
<p>
Start with the "models hub"
</p>

<p>
Here contains AI models created by the community/ HF users.
</p>
<ul class="org-ul">
<li>a little overwhelming interface, I will explain it in a moment.</li>
<li>models are trained or fine-tuned, can then published to the "hub".</li>
<li>navigation goes from left to right
<ul class="org-ul">
<li>on left side, there's tasks, like text classification. Also
libraries, datasets, etc. Later we will choose one?
What is the <b>difference between training and fine-tuning</b>?
<ul class="org-ul">
<li>training
<ul class="org-ul">
<li>the creation of a "base" model. It requires lots, LOTS of data,
gigabites of data, and compute power. It takes days, sometimes
longer.</li>
</ul></li>
<li>fine-tuning:
<ul class="org-ul">
<li>taking a base model, which has already been trained (like BERT)
and training it further, with a much smaller dataset that is
focused on a specific topic.</li>
<li>customizing the model to work for a particular topic or kind of
data. 
<ul class="org-ul">
<li>finBERT for sentiment analysis of financial data.</li>
</ul></li>
</ul></li>
</ul></li>
<li>on right side, there's models. We are going to narrow down the
models.</li>
</ul></li>
</ul>

<p>
Filter results by "most downloaded", notice the difference:
</p>
<ul class="org-ul">
<li>"most downloaded":
<ul class="org-ul">
<li>Wav2Vec - audio to vector, speech to text.</li>
<li>RoBERTa - one of the many permutations of BERT, you'll see. First
model to put into practice the Transformer architecture.</li>
</ul></li>
</ul>

<p>
Filter results by "most liked", you'll see things that may appear
familiar. 
</p>
<ul class="org-ul">
<li><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5">Stable Diffusion</a> - image generator model.</li>
<li>models by Meta, aka Facebook.</li>
</ul>

<p>
Scroll down, and look for a model called "gpt-neo". Or search for it.
</p>
<ul class="org-ul">
<li><a href="https://huggingface.co/EleutherAI/gpt-neo-125m">gpt-neo-125m</a>
<ul class="org-ul">
<li>a model developed by EleutherAI, a non-profit research lab.</li>
<li>part of a larger family of models named "gpt-neo" with the size
at the end.
<ul class="org-ul">
<li>search "gpt-neo" and you'll see the list.</li>
</ul></li>
</ul></li>
<li>notice "<b>model size</b>". How big is it?
<ul class="org-ul">
<li>125m parameters. That's how many inputs goes into
inference. Includes things like word vectors, but also different
kinds of inputs.
<ul class="org-ul">
<li>size is an indication of complexity. The larger the size, the
more likely that the model will preform well.</li>
</ul></li>
</ul></li>
<li>notice the "<b>license</b>":
<ul class="org-ul">
<li>MIT license. Very permissive, part of the "Open Source"
licenses.
<ul class="org-ul">
<li>the model is totally open to download and modify as you wish,
even for commercial purposes.</li>
</ul></li>
<li>practice running inference here for a few mintues.
<ul class="org-ul">
<li>anything that you notice about the results?
<ul class="org-ul">
<li>it's repetitive.
<ul class="org-ul">
<li>the repetition problem is caused by the traits of our
language itself.</li>
<li>it generates words that have the highest likelihood. The
words that have this likelihood tend to be the same ones,
over and over again.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p>
Go back to most download, select <a href="https://huggingface.co/meta-llama/Llama-2-7b">Llama</a>,
</p>
<ul class="org-ul">
<li>by Meta, aka Facebook.</li>
<li>in terms of licensing, this is the most restrictive, by far.
<ul class="org-ul">
<li>Meta champions this model as "open source" but it is nothing like
that. The license prevents you from making anything that can
compete with them.
<ul class="org-ul">
<li>"open source" vs open access models: not everything open access
is open source!</li>
<li>not sharing the model’s training data or the code used to train
it unless you sign their agreement.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org265c533" class="outline-4">
<h4 id="org265c533"><span class="section-number-4">2.4.2.</span> "datasets hub"</h4>
<div class="outline-text-4" id="text-2-4-2">
<p>
Besides models, 🤗 offers Datasets.
</p>
<ul class="org-ul">
<li>these datasets are used to fine-tune (and also train and evaluate)
models.</li>
<li>"training data"</li>
</ul>

<p>
Before diving in, important to consider how these datasets were
created. 
</p>
<ul class="org-ul">
<li>there are a lot of <b>ethical issues</b> with the ways that datasets for
training are generated.
<ul class="org-ul">
<li>where the data comes from</li>
<li>and how they are cleanded (or not cleaned).</li>
</ul></li>
</ul>

<p>
Where do we get most of the data used to train these models? 
</p>
<ul class="org-ul">
<li>scraped from the internet, most of them.</li>
</ul>

<p>
Search "bookcorpus"
</p>
<ul class="org-ul">
<li>click on <a href="https://huggingface.co/datasets/bookcorpus">bookcorpus</a> to open the dataset page
<ul class="org-ul">
<li>can see that it consists of sentences from books.</li>
<li>can also see that it's been used to train some of the most
influential models out there. The Berts!</li>
</ul></li>
<li>Unfortunately, this dataset violates copyright.
<ul class="org-ul">
<li>scrapes all the free books from smashwords.com, even those that
have copyright licenses to not reproduce information.</li>
<li>the authors obviously did not consent to their work being scraped.</li>
</ul></li>
</ul>

<p>
This points to a major issue being explored in the courts today, the
issue of whether the training data violates copyright.
</p>
<ul class="org-ul">
<li>The makers of these models argue that the use of training data falls
under the "fair use" exception to copyright law.
<ul class="org-ul">
<li>Something can be used if it is for educational purposes.</li>
</ul></li>
</ul>

<p>
Scraped from the internet also means bias
</p>
<ul class="org-ul">
<li>contains all the worst parts of the internet, too. All of the
discrimination and violence.</li>
<li><p>
you cannot automate the removal of bias and discrimination,
because it can be situational, nuanced.
</p>
<ul class="org-ul">
<li>I might say something that is offensive, whereas if someone
else, from different background or in a different context says
the same thing, it's not offensive.</li>
</ul>
<ul class="org-ul">
<li>attempts to automate this have failed:
<ul class="org-ul">
<li>"List of Dirty Obscene&#x2026;"</li>
</ul></li>
</ul></li>
<li>there's a race to get these products out there, so people aren't
taking the time needed to adequately clean the data and make sure
it's safe. That's just a fact.
<ul class="org-ul">
<li>RLHF - "reinforcement learning from human feedback"</li>
</ul></li>
</ul>

<p>
Go back to main datasets page, select <a href="https://huggingface.co/datasets/truthful_qa">TruthfulQA</a>
</p>
<ul class="org-ul">
<li>this is a "benchmark" dataset, can also be used for training. 
<ul class="org-ul">
<li>it's meant to measure how well models perform.</li>
<li>in this case, to measure how truthful the output responses are to
certain prompts.</li>
</ul></li>
<li>meant to measure "truth" of a model. If a model scores well on this
benchmark, they are considered truthful.
<ul class="org-ul">
<li>these are the ways we are assessing our model's performance.</li>
</ul></li>
</ul>

<p>
Something to keep in mind! There's a lot of work to be done developing
datasets, for fine-tuning and benchmarking. 
</p>
</div>
</div>

<div id="outline-container-orgf5d133c" class="outline-4">
<h4 id="orgf5d133c"><span class="section-number-4">2.4.3.</span> think/pair/share activity</h4>
<div class="outline-text-4" id="text-2-4-3">
<p>
Something about why it is so difficult to automate bias?
(I will have given them clues to this throughout the first sections). 
</p>
</div>
</div>
</div>
<div id="outline-container-org22e28df" class="outline-3">
<h3 id="org22e28df"><span class="section-number-3">2.5.</span> inference with python on colab: abstraction &amp; data:</h3>
<div class="outline-text-3" id="text-2-5">
<p>
Now that you have a sense of how things work on the HF website, we are
going to practice running inference on Google Colab.
</p>

<p>
Our goal is to create a text generator, using Python code, taking the
following steps: 
</p>
<ul class="org-ul">
<li>Will use the model, "<a href="https://huggingface.co/EleutherAI/gpt-neo-125m">gpt-neo-125m</a>", and write code that imports this
model into the colab coding space.</li>
<li>Then we will write code to process an input text, and generate an
output, a continuation.</li>
<li>Finally, we will import a dataset from the library and practice
running inference with it.</li>
</ul>

<p>
We'll talk about some programming concepts along the way, like
variables and data types. Accessing data from different types and
structures. 
</p>
<ul class="org-ul">
<li>how programming languages abstract data through variables, learning
how to read these layers of abstraction.</li>
<li>how programming languages store data into structures, and how to
access or manipulate that data.</li>
</ul>
</div>

<div id="outline-container-orgd4938e8" class="outline-4">
<h4 id="orgd4938e8"><span class="section-number-4">2.5.1.</span> google colab, REPL, variables:</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
<a href="https://colab.research.google.com/">https://colab.research.google.com/</a>
</p>

<p>
A cloud computing platform, where you can run code directly in the
browser.
</p>

<p>
Python can be difficult to install and configure, it's system
specific. Also distributions are large and take up space on your
laptop. Cloud computing takes away these issues.
</p>
<ul class="org-ul">
<li>one particular plus is the colab offers computing power that is
strong enough to handle these models.</li>
</ul>

<p>
Basic interface:
</p>
<ul class="org-ul">
<li>cells to run the code, an "expression"</li>
</ul>

<div class="org-src-container">
<pre class="src src-python">1 + 1
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">run code by pressing shift-return, or the play button. </span>

<span style="color: #4eee94;">x</span> = 5

<span style="color: #4eee94;">y</span> = 7

x + y

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">all variables saved. </span>

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">"interactive mode" - evaluate the expression, print result, back to</span>
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">prompt for more expressions.</span>

</pre>
</div>
</div>
</div>

<div id="outline-container-org71cabc7" class="outline-4">
<h4 id="org71cabc7"><span class="section-number-4">2.5.2.</span> import the models</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
on the toolbar, where it says RAM DISK, change the hardware accelator
to GPU.
</p>

<p>
Then go back to the models page.
</p>

<p>
Search for gpt-neo, select 125m. On the top right, click on "Use in
Transformers."
</p>

<p>
Copy that code, and paste it to your google colab cell.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">Use a pipeline as a high-level helper</span>
<span style="color: #00bfff;">from</span> transformers <span style="color: #00bfff;">import</span> pipeline

<span style="color: #4eee94;">pipe</span> = pipeline(<span style="color: #deb887;">"text-generation"</span>, model=<span style="color: #deb887;">"EleutherAI/gpt-neo-125m"</span>)
</pre>
</div>

<p>
Here we have a function, called <code>pipeline()</code>, which takes parameters (a
fancy word for input).
</p>

<p>
The parameters specify the task and the model that we will be using.
</p>

<p>
We save the function to a variable called <code>pipe</code>, which we will later
use to process our prompt. 
</p>
</div>
</div>

<div id="outline-container-orgc50d47f" class="outline-4">
<h4 id="orgc50d47f"><span class="section-number-4">2.5.3.</span> run inference</h4>
<div class="outline-text-4" id="text-2-5-3">
<p>
Now we are going to "run inference."
</p>

<p>
First, we will type up a prompt, and save it to a variable
<code>prompt</code>. Then we will pass that prompt to the <code>pipe</code> variable that we
created before, saving the output to a new variable, called <code>output</code>. 
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #4eee94;">prompt</span> = <span style="color: #deb887;">"Hello, my name is Filipa and"</span>

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">we want the length to be 50 characters at the most </span>
<span style="color: #4eee94;">output</span> = pipe(prompt, max_length = 50)
</pre>
</div>

<p>
Here we see the levels of abstraction at play. Saving the pipeline
function to a new variable, then the prompt text to a variable, and
passing that prompt into the pipe.
</p>

<p>
Now let's look at the response, and inspect the data structure
contained within it, which is a <code>list</code>.
</p>

<p>
<code>list</code> is a collection of objects, or bits of information. So our
output is saved as this collection type of object.
</p>

<div class="org-src-container">
<pre class="src src-python">
output
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">[{'generated_text': "Hello, my name is Filipa and I'm a newbie in</span>
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">the world of web development."}]</span>

<span style="color: #f08080;">type</span>(output)
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">list</span>

</pre>
</div>

<p>
What if we wanted to extract just the output text, not the rest of the
data, how would we go about it?
</p>

<p>
We are going to examine this list to see what else is contained
inside. For that we will use "indexing."
</p>

<p>
Indexing is picking out object by their position within another
object, like a list (though it also works for strings). The first item
is zero, the second item is 1, and so on.
</p>

<p>
Does anybody know what we start with zero? (Because it is based on
offsets. Think like a computer. The first item is the starting place,
we don't have to move anywhere to access it. But the second item, we
have to move one place to the right, so it's 1). 
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #4eee94;">name</span> = Filipa
name[0]
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">F</span>
name[1]
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">i</span>

output[0]
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">{'generated_text': "Hello, my name is Filipa and I'm a newbie in the</span>
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">world of web development."}</span>

<span style="color: #f08080;">type</span>(output[0])
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">dict</span>

</pre>
</div>

<p>
Now we are getting closer, we got rid of the brackets. Inside this
list, we actually have a new data type, called a <code>dict</code>. This stands
for data structured into key:value pairs.
</p>

<p>
Let's look at an example:
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">key, value pairs</span>

<span style="color: #4eee94;">filipa</span> = {
    <span style="color: #deb887;">'first_name'</span>: <span style="color: #deb887;">'filipa'</span>
    <span style="color: #deb887;">'last_name'</span>: <span style="color: #deb887;">'calado'</span>,
    <span style="color: #deb887;">'job'</span>: <span style="color: #deb887;">'library'</span>,
    <span style="color: #deb887;">'age'</span>: <span style="color: #deb887;">'34'</span>,
    <span style="color: #deb887;">'degree'</span>: <span style="color: #deb887;">'literature'</span>
}


<span style="color: #f08080;">type</span>(filipa)
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">dict</span>

</pre>
</div>

<p>
To get items from a dict, you use a different method, accessing them
by their keys.
</p>

<div class="org-src-container">
<pre class="src src-python">filipa[<span style="color: #deb887;">'first_name'</span>]
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">filipa</span>

filipa[<span style="color: #deb887;">'degree'</span>]
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">literature</span>

</pre>
</div>

<p>
So, we can combine what we know about list indexing and accessing
items in a dict by keys to pull out just the response text
</p>

<div class="org-src-container">
<pre class="src src-python">
output[0][<span style="color: #deb887;">'generated_text'</span>]

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">then we can save it to a variable!</span>

<span style="color: #4eee94;">text</span> = output[0][<span style="color: #deb887;">'generated_text'</span>]

</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: CaladoF</p>
<p class="date">Created: 2024-02-22 Thu 15:26</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>